{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Optim & Criterion\n",
    "\n",
    "- Loss (손실 계산)\n",
    "- Update (parameter 업데이트) => torch.optim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 순서\n",
    "\n",
    "    - Import\n",
    "    - Dataset 만들기\n",
    "    - Model 만들기\n",
    "    - Optim, Loss 함수 결정하기\n",
    "        - Optimizer : parameter를 넣어주어야 함. model 클래스의 model.parameters()\n",
    "    - 학습을 위한 반복문 작성\n",
    "    - 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # 무조건 써야 함.\n",
    "        super(my_network, self).__init__()\n",
    "        \n",
    "        # 사용할 함수들을 정의\n",
    "        self.conv1 = nn.Conv2d(3, 64, 5)\n",
    "        self.conv2 = nn.Conv2d(64, 30, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(30*5*5, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "    # input이 여러개 일 경우도 있음. x, y, 등등..\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Network의 forward를 정의하는 장소\n",
    "        x = F.relu(self.conv1(x), inplace=True)\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        x = F.relu(self.conv2(x), inplace=True)\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        \n",
    "        # FC에 집어넣을 때는, 일렬 형태에 집어넣어야 함\n",
    "        # 30 * 5 * 5 크기의 데이터에서 배치사이즈만큼 놓고\n",
    "        # flatten 시켜주는 부분임.\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x), inplace=True)\n",
    "        x = F.relu(self.fc2(x), inplace=True)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\",\n",
    "                                       train=True,\n",
    "                                       download=True,\n",
    "                                       transform=trans)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\",\n",
    "                                      train=False,\n",
    "                                      download=True,\n",
    "                                      transform=trans)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=8, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net = my_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(my_net.parameters(), lr = 0.001, momentum = 0.9)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 => loss : 1.989 \n",
      "64 => loss : 2.047 \n",
      "128 => loss : 2.149 \n",
      "192 => loss : 1.804 \n",
      "256 => loss : 2.250 \n",
      "320 => loss : 2.339 \n",
      "384 => loss : 1.809 \n",
      "448 => loss : 1.541 \n",
      "512 => loss : 2.195 \n",
      "576 => loss : 2.117 \n",
      "640 => loss : 1.966 \n",
      "704 => loss : 1.467 \n",
      "768 => loss : 1.589 \n",
      "832 => loss : 1.924 \n",
      "896 => loss : 1.502 \n",
      "960 => loss : 1.456 \n",
      "1024 => loss : 1.996 \n",
      "1088 => loss : 1.430 \n",
      "1152 => loss : 1.091 \n",
      "1216 => loss : 1.566 \n",
      "1280 => loss : 1.536 \n",
      "1344 => loss : 1.719 \n",
      "1408 => loss : 1.039 \n",
      "1472 => loss : 1.925 \n",
      "1536 => loss : 2.064 \n",
      "1600 => loss : 1.202 \n",
      "1664 => loss : 0.997 \n",
      "1728 => loss : 2.166 \n",
      "1792 => loss : 1.656 \n",
      "1856 => loss : 1.952 \n",
      "1920 => loss : 1.817 \n",
      "1984 => loss : 1.514 \n",
      "2048 => loss : 1.668 \n",
      "2112 => loss : 2.104 \n",
      "2176 => loss : 1.824 \n",
      "2240 => loss : 1.091 \n",
      "2304 => loss : 2.254 \n",
      "2368 => loss : 0.965 \n",
      "2432 => loss : 1.667 \n",
      "2496 => loss : 1.772 \n",
      "2560 => loss : 1.838 \n",
      "2624 => loss : 1.879 \n",
      "2688 => loss : 1.480 \n",
      "2752 => loss : 1.705 \n",
      "2816 => loss : 1.550 \n",
      "2880 => loss : 2.261 \n",
      "2944 => loss : 2.071 \n",
      "3008 => loss : 1.283 \n",
      "3072 => loss : 0.889 \n",
      "3136 => loss : 1.549 \n",
      "3200 => loss : 1.169 \n",
      "3264 => loss : 1.047 \n",
      "3328 => loss : 1.371 \n",
      "3392 => loss : 1.122 \n",
      "3456 => loss : 1.412 \n",
      "3520 => loss : 0.999 \n",
      "3584 => loss : 1.504 \n",
      "3648 => loss : 1.550 \n",
      "3712 => loss : 2.397 \n",
      "3776 => loss : 0.863 \n",
      "3840 => loss : 0.982 \n",
      "3904 => loss : 1.758 \n",
      "3968 => loss : 1.950 \n",
      "4032 => loss : 1.019 \n",
      "4096 => loss : 1.609 \n",
      "4160 => loss : 1.257 \n",
      "4224 => loss : 1.386 \n",
      "4288 => loss : 1.561 \n",
      "4352 => loss : 1.468 \n",
      "4416 => loss : 1.840 \n",
      "4480 => loss : 1.604 \n",
      "4544 => loss : 1.198 \n",
      "4608 => loss : 1.351 \n",
      "4672 => loss : 1.535 \n",
      "4736 => loss : 1.232 \n",
      "4800 => loss : 1.204 \n",
      "4864 => loss : 1.093 \n",
      "4928 => loss : 0.659 \n",
      "4992 => loss : 1.664 \n",
      "5056 => loss : 1.319 \n",
      "5120 => loss : 1.337 \n",
      "5184 => loss : 1.504 \n",
      "5248 => loss : 1.849 \n",
      "5312 => loss : 1.690 \n",
      "5376 => loss : 0.980 \n",
      "5440 => loss : 1.722 \n",
      "5504 => loss : 1.813 \n",
      "5568 => loss : 1.114 \n",
      "5632 => loss : 1.651 \n",
      "5696 => loss : 1.052 \n",
      "5760 => loss : 2.310 \n",
      "5824 => loss : 1.802 \n",
      "5888 => loss : 0.949 \n",
      "5952 => loss : 1.179 \n",
      "6016 => loss : 1.355 \n",
      "6080 => loss : 2.324 \n",
      "6144 => loss : 1.075 \n",
      "6208 => loss : 1.651 \n",
      "0 => loss : 1.547 \n",
      "64 => loss : 1.246 \n",
      "128 => loss : 0.814 \n",
      "192 => loss : 0.895 \n",
      "256 => loss : 1.264 \n",
      "320 => loss : 0.683 \n",
      "384 => loss : 0.813 \n",
      "448 => loss : 1.383 \n",
      "512 => loss : 1.155 \n",
      "576 => loss : 1.453 \n",
      "640 => loss : 1.430 \n",
      "704 => loss : 1.176 \n",
      "768 => loss : 1.943 \n",
      "832 => loss : 1.829 \n",
      "896 => loss : 1.105 \n",
      "960 => loss : 2.099 \n",
      "1024 => loss : 1.026 \n",
      "1088 => loss : 0.740 \n",
      "1152 => loss : 0.845 \n",
      "1216 => loss : 1.405 \n",
      "1280 => loss : 1.601 \n",
      "1344 => loss : 1.829 \n",
      "1408 => loss : 0.989 \n",
      "1472 => loss : 1.345 \n",
      "1536 => loss : 1.008 \n",
      "1600 => loss : 0.830 \n",
      "1664 => loss : 1.222 \n",
      "1728 => loss : 1.393 \n",
      "1792 => loss : 1.709 \n",
      "1856 => loss : 1.732 \n",
      "1920 => loss : 1.293 \n",
      "1984 => loss : 1.498 \n",
      "2048 => loss : 1.707 \n",
      "2112 => loss : 1.230 \n",
      "2176 => loss : 1.015 \n",
      "2240 => loss : 0.885 \n",
      "2304 => loss : 0.950 \n",
      "2368 => loss : 0.485 \n",
      "2432 => loss : 1.709 \n",
      "2496 => loss : 1.986 \n",
      "2560 => loss : 1.295 \n",
      "2624 => loss : 0.841 \n",
      "2688 => loss : 1.273 \n",
      "2752 => loss : 1.222 \n",
      "2816 => loss : 0.982 \n",
      "2880 => loss : 1.138 \n",
      "2944 => loss : 0.905 \n",
      "3008 => loss : 1.402 \n",
      "3072 => loss : 1.242 \n",
      "3136 => loss : 1.166 \n",
      "3200 => loss : 2.001 \n",
      "3264 => loss : 0.846 \n",
      "3328 => loss : 0.773 \n",
      "3392 => loss : 1.507 \n",
      "3456 => loss : 1.032 \n",
      "3520 => loss : 1.156 \n",
      "3584 => loss : 0.834 \n",
      "3648 => loss : 1.303 \n",
      "3712 => loss : 1.575 \n",
      "3776 => loss : 0.345 \n",
      "3840 => loss : 1.192 \n",
      "3904 => loss : 1.250 \n",
      "3968 => loss : 1.042 \n",
      "4032 => loss : 0.931 \n",
      "4096 => loss : 1.268 \n",
      "4160 => loss : 0.781 \n",
      "4224 => loss : 0.681 \n",
      "4288 => loss : 0.900 \n",
      "4352 => loss : 1.519 \n",
      "4416 => loss : 1.054 \n",
      "4480 => loss : 1.505 \n",
      "4544 => loss : 1.186 \n",
      "4608 => loss : 1.113 \n",
      "4672 => loss : 0.870 \n",
      "4736 => loss : 0.550 \n",
      "4800 => loss : 0.769 \n",
      "4864 => loss : 1.787 \n",
      "4928 => loss : 0.447 \n",
      "4992 => loss : 0.812 \n",
      "5056 => loss : 0.897 \n",
      "5120 => loss : 0.896 \n",
      "5184 => loss : 1.793 \n",
      "5248 => loss : 1.566 \n",
      "5312 => loss : 1.271 \n",
      "5376 => loss : 1.956 \n",
      "5440 => loss : 1.211 \n",
      "5504 => loss : 1.235 \n",
      "5568 => loss : 0.740 \n",
      "5632 => loss : 0.844 \n",
      "5696 => loss : 1.339 \n",
      "5760 => loss : 1.468 \n",
      "5824 => loss : 1.309 \n",
      "5888 => loss : 0.930 \n",
      "5952 => loss : 0.425 \n",
      "6016 => loss : 1.379 \n",
      "6080 => loss : 0.580 \n",
      "6144 => loss : 0.935 \n",
      "6208 => loss : 1.038 \n",
      "0 => loss : 0.891 \n",
      "64 => loss : 0.704 \n",
      "128 => loss : 0.723 \n",
      "192 => loss : 0.974 \n",
      "256 => loss : 0.786 \n",
      "320 => loss : 1.046 \n",
      "384 => loss : 0.970 \n",
      "448 => loss : 0.945 \n",
      "512 => loss : 0.823 \n",
      "576 => loss : 1.108 \n",
      "640 => loss : 1.524 \n",
      "704 => loss : 0.342 \n",
      "768 => loss : 0.918 \n",
      "832 => loss : 1.236 \n",
      "896 => loss : 0.846 \n",
      "960 => loss : 0.971 \n",
      "1024 => loss : 1.084 \n",
      "1088 => loss : 0.889 \n",
      "1152 => loss : 1.286 \n",
      "1216 => loss : 2.007 \n",
      "1280 => loss : 1.983 \n",
      "1344 => loss : 1.213 \n",
      "1408 => loss : 1.340 \n",
      "1472 => loss : 0.529 \n",
      "1536 => loss : 1.724 \n",
      "1600 => loss : 1.447 \n",
      "1664 => loss : 0.868 \n",
      "1728 => loss : 1.395 \n",
      "1792 => loss : 0.704 \n",
      "1856 => loss : 1.397 \n",
      "1920 => loss : 0.857 \n",
      "1984 => loss : 0.691 \n",
      "2048 => loss : 0.834 \n",
      "2112 => loss : 0.599 \n",
      "2176 => loss : 0.337 \n",
      "2240 => loss : 0.758 \n",
      "2304 => loss : 1.597 \n",
      "2368 => loss : 1.698 \n",
      "2432 => loss : 0.645 \n",
      "2496 => loss : 1.025 \n",
      "2560 => loss : 0.639 \n",
      "2624 => loss : 0.734 \n",
      "2688 => loss : 0.791 \n",
      "2752 => loss : 0.607 \n",
      "2816 => loss : 0.925 \n",
      "2880 => loss : 1.136 \n",
      "2944 => loss : 0.828 \n",
      "3008 => loss : 1.023 \n",
      "3072 => loss : 0.432 \n",
      "3136 => loss : 0.923 \n",
      "3200 => loss : 1.009 \n",
      "3264 => loss : 1.228 \n",
      "3328 => loss : 1.076 \n",
      "3392 => loss : 1.105 \n",
      "3456 => loss : 0.570 \n",
      "3520 => loss : 0.906 \n",
      "3584 => loss : 1.251 \n",
      "3648 => loss : 0.718 \n",
      "3712 => loss : 0.433 \n",
      "3776 => loss : 0.980 \n",
      "3840 => loss : 0.797 \n",
      "3904 => loss : 0.617 \n",
      "3968 => loss : 0.604 \n",
      "4032 => loss : 0.968 \n",
      "4096 => loss : 0.290 \n",
      "4160 => loss : 0.876 \n",
      "4224 => loss : 1.847 \n",
      "4288 => loss : 0.493 \n",
      "4352 => loss : 0.700 \n",
      "4416 => loss : 0.448 \n",
      "4480 => loss : 0.715 \n",
      "4544 => loss : 0.832 \n",
      "4608 => loss : 0.784 \n",
      "4672 => loss : 0.815 \n",
      "4736 => loss : 0.751 \n",
      "4800 => loss : 0.807 \n",
      "4864 => loss : 1.127 \n",
      "4928 => loss : 1.366 \n",
      "4992 => loss : 1.671 \n",
      "5056 => loss : 0.825 \n",
      "5120 => loss : 0.745 \n",
      "5184 => loss : 0.754 \n",
      "5248 => loss : 1.102 \n",
      "5312 => loss : 0.464 \n",
      "5376 => loss : 0.636 \n",
      "5440 => loss : 1.055 \n",
      "5504 => loss : 0.942 \n",
      "5568 => loss : 2.160 \n",
      "5632 => loss : 1.133 \n",
      "5696 => loss : 1.033 \n",
      "5760 => loss : 1.059 \n",
      "5824 => loss : 0.577 \n",
      "5888 => loss : 0.638 \n",
      "5952 => loss : 0.794 \n",
      "6016 => loss : 0.818 \n",
      "6080 => loss : 0.271 \n",
      "6144 => loss : 0.395 \n",
      "6208 => loss : 0.977 \n",
      "train over\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 3\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        out = my_net(inputs)\n",
    "        loss = loss_function(out, labels)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        if i % 64 == 0:\n",
    "            print(\"%d => loss : %.3f \" % (i, loss))\n",
    "print(\"train over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 66.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = my_net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print(\"Accuracy of the network on the 10000 test images: %f\" % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
