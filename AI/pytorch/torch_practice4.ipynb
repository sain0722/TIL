{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset\n",
    "\n",
    "- torchvision -> ImageFolder\n",
    "- 원하는 형태의 데이터로 가공\n",
    "- Custom Dataset의 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\",\n",
    "                                       train=True,\n",
    "                                       download=True,\n",
    "                                       transform=trans)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\",\n",
    "                                      train=False,\n",
    "                                      download=True,\n",
    "                                      transform=trans)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=8, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-59dfa0b9ad09>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-59dfa0b9ad09>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    def __len__(self):\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class my_dataset(touch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, x, transforms=None):\n",
    "        \n",
    "        # 데이터 선처리를 해준다\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        # 데이터셋의 길이를 반환한다\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # 데이터셋에서 한개의 데이터를 가져오는 함수\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Network를 더 쉽게 만들기\n",
    "- Model 저장하고 불러다가 다시 쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\",\n",
    "                                       train=True,\n",
    "                                       download=True,\n",
    "                                       transform=trans)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\",\n",
    "                                      train=False,\n",
    "                                      download=True,\n",
    "                                      transform=trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, 3),\n",
    "            nn.Conv2d(128, 128, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 256, 3),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer2_1 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 7, 1, 2),\n",
    "            nn.Conv2d(512, 64, 1),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "             \n",
    "        self.layer2_2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 5, 1, 1),\n",
    "            nn.Conv2d(512, 64, 1),\n",
    "            nn.MaxPool2d(2)\n",
    "        )        \n",
    "        \n",
    "        self.layer2_3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3),\n",
    "            nn.Conv2d(512, 64, 1),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(3*64*4*4, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(x.data.shape)\n",
    "        x = self.layer1(x)\n",
    "        x1 = self.layer2_1(x)\n",
    "        x2 = self.layer2_2(x)\n",
    "        x3 = self.layer2_3(x)\n",
    "        \n",
    "        # 1은 dimension을 의미.\n",
    "        # x값의 형태(x.shape) == batch_size * Ch * H * W\n",
    "        # 1이라고 하는 것은 \"채널\"을 기준으로 합치라는 의미.(x.shape의 인덱스)\n",
    "        x = torch.cat((x1, x2, x3), 1)\n",
    "        \n",
    "        # 채널 이하의 것은 한줄로 펴라. (Height, Width)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1, 3, 32, 32)\n",
    "print(a.shape)\n",
    "a = Variable(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "network = Net()\n",
    "out = network(a)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0144,  0.0261, -0.0229, -0.0358,  0.0162, -0.0306,  0.0121, -0.0137,\n",
      "          0.0285,  0.0013]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# out의 value값.\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네트워크 저장\n",
    "\n",
    "torch.save(network.state_dict(), './cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load('./cnn.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "tensor([[ 0.0144,  0.0261, -0.0229, -0.0358,  0.0162, -0.0306,  0.0121, -0.0137,\n",
      "          0.0285,  0.0013]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "out = model(a)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0144,  0.0261, -0.0229, -0.0358,  0.0162, -0.0306,  0.0121, -0.0137,\n",
      "          0.0285,  0.0013]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "vis = visdom.Visdom()\n",
    "\n",
    "textwindow = vis.text(\"Hello Pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500):\n",
    "    vis.line(Y=torch.rand(1), X=np.array([i+5]), win=plot, update=\"append\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
